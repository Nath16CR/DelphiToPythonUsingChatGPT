{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP52dHuA37jEd/FdwkUxwQe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josecascanteGL/DelphiToPythonUsingChatGPT/blob/main/DelphiCodeExtractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "7qkH9X4ZlJuv"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import base64\n",
        "import datetime\n",
        "import json\n",
        "import chardet\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read secrets**"
      ],
      "metadata": {
        "id": "a23c1iuRWVMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/secrets.json', 'r') as f:\n",
        "  secrets = json.load(f)\n",
        "\n",
        "# Assign variables directly\n",
        "github_api_key = secrets.get('github_api_key')\n",
        "openai_api_key = secrets.get('openai_api_key')\n",
        "open_ai_api_path = 'https://api.openai.com/v1/chat/completions'"
      ],
      "metadata": {
        "id": "nhzVvYfNWTmL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Global declarations**"
      ],
      "metadata": {
        "id": "C2vHWZT8ZqnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/config.json', 'r') as f:\n",
        "  config = json.load(f)\n",
        "\n",
        "destination_repo_owner = config.get(\"DestinationRepoOwner\")\n",
        "destination_repo_name = config.get(\"DestinationRepoName\")\n",
        "source_repo_owner = config.get(\"SourceRepoOwner\")\n",
        "source_repo_name = config.get(\"SourceRepoName\")\n",
        "source_path = config.get(\"SourcePath\")\n",
        "github_base_url = 'https://api.github.com/repos'\n",
        "git_headers = {'Authorization': f'Bearer {github_api_key}'}\n",
        "\n",
        "print(config)"
      ],
      "metadata": {
        "id": "pJND9fdnlYYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a440d227-42bf-4443-e8d9-bbca03f648f5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'SourceRepoOwner': 'DeveloppeurPascal', 'SourceRepoName': 'Delphi-samples', 'SourcePath': 'Console-Samples/010-StringComparison', 'DestinationRepoOwner': 'josecascanteGL', 'DestinationRepoName': 'chatGptPlayground'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_file_content(git_response):\n",
        "    # Step 1: Extract the base64-encoded content from GitHub\n",
        "    content_b64 = git_response.json().get('content', '')\n",
        "    content_bytes = base64.b64decode(content_b64)\n",
        "\n",
        "    # Step 2: Try using the encoding from the response if available\n",
        "    if hasattr(git_response, 'encoding') and git_response.encoding:\n",
        "        try:\n",
        "            return content_bytes.decode(git_response.encoding)\n",
        "        except UnicodeDecodeError:\n",
        "            print(f\"Failed to decode with reported encoding: {git_response.encoding}\")\n",
        "\n",
        "    # Step 3: Fallback to auto-detecting encoding using chardet\n",
        "    detected = chardet.detect(content_bytes)\n",
        "    encoding = detected.get(\"encoding\", \"utf-8\")\n",
        "    confidence = detected.get(\"confidence\", 0)\n",
        "\n",
        "    try:\n",
        "      if encoding is None:\n",
        "        encoding = \"utf-8\"\n",
        "      return content_bytes.decode(encoding)\n",
        "    except UnicodeDecodeError:\n",
        "        print(f\"Failed to decode with detected encoding: {encoding} (confidence: {confidence})\")\n",
        "        # As a last resort, ignore errors\n",
        "        return content_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "def GenerateTimestamp():\n",
        "  now = datetime.datetime.now()\n",
        "  timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
        "  return str(timestamp)\n",
        "\n",
        "def RemoveExtension(filename: str) -> str:\n",
        "  return os.path.splitext(filename)[0]\n"
      ],
      "metadata": {
        "id": "LCj-boigp45b"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions definitions"
      ],
      "metadata": {
        "id": "BHJ0LD1tZ11Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def GetFolderFiles(folder_name):\n",
        "  github_origin_url = f'{github_base_url}/{source_repo_owner}/{source_repo_name}/contents/{folder_name}'\n",
        "  response = requests.get(github_origin_url, headers=git_headers)\n",
        "  if response.status_code == 200:\n",
        "    files_data = response.json()\n",
        "    file_names = [item['path'] for item in files_data if item['type'] == 'file']\n",
        "    return file_names\n",
        "  else:\n",
        "    print(f\"Error getting files in folder {github_origin_url}: {response.status_code} - {response.text}\")\n",
        "    return []\n",
        "\n",
        "\n",
        "def GetSubFolders(folder_name):\n",
        "  github_origin_url = f'{github_base_url}/{source_repo_owner}/{source_repo_name}/contents/{folder_name}'\n",
        "  response = requests.get(github_origin_url, headers=git_headers)\n",
        "  if response.status_code == 200:\n",
        "    files_data = response.json()\n",
        "    file_names = [item['path'] for item in files_data if item['type'] == 'dir']\n",
        "    return file_names\n",
        "  else:\n",
        "    print(f\"Error getting folder {github_origin_url}: {response.status_code} - {response.text}\")\n",
        "    return []\n",
        "\n",
        "def ReadFileInGithub(file_name):\n",
        "  github_origin_url = f'{github_base_url}/{source_repo_owner}/{source_repo_name}/contents/{file_name}'\n",
        "  response = requests.get(github_origin_url, headers=git_headers)\n",
        "  if response.status_code != 200:\n",
        "    print(f\"Error reading file {github_origin_url}: {response.status_code} - {response.text}\")\n",
        "  return response\n",
        "\n",
        "def SendToGpt(content, instruction, gpt_model):\n",
        "  gpt_headers = {\n",
        "    'Authorization': f'Bearer {openai_api_key}',\n",
        "    'Content-Type': 'application/json'\n",
        "  }\n",
        "  chat_payload = {\n",
        "    'model': gpt_model,\n",
        "    'messages': [{'role': 'user', 'content': f'{instruction}.:\\n{content}'}]\n",
        "  }\n",
        "\n",
        "  chat_response = requests.post(open_ai_api_path, headers=gpt_headers, json=chat_payload)\n",
        "  chat_result = chat_response\n",
        "  return chat_result\n",
        "\n",
        "def SendToGitHub(content, file_name, output_file_type):\n",
        "  new_content = base64.b64encode(content.encode('utf-8')).decode('utf-8')\n",
        "  github_destination_url = f'{github_base_url}/{destination_repo_owner}/{destination_repo_name}/contents/Generated/{time_stamp}/{RemoveExtension(file_name)}{output_file_type}'\n",
        "\n",
        "  update_payload = {\n",
        "      'message': 'Generated from ChatGPT',\n",
        "      'content': new_content\n",
        "  }\n",
        "  update_response = requests.put(github_destination_url, headers=git_headers, json=update_payload)\n",
        "  print(update_response.json())\n",
        "\n",
        "def ProcessFiles(files_to_process, instruction, gpt_model, input_file_type, output_file_type):\n",
        "  for file_name in files_to_process:\n",
        "    if file_name.lower().endswith(input_file_type):\n",
        "      git_response = ReadFileInGithub(file_name)\n",
        "      if git_response.status_code == 200:\n",
        "        file_content = decode_file_content(git_response)\n",
        "        print(f\"Sending {files_to_process} to gpt\")\n",
        "        chat_result = SendToGpt(file_content, instruction, gpt_model)\n",
        "        if chat_result.status_code == 200:\n",
        "          chat_result = chat_result.json()['choices'][0]['message']['content']\n",
        "          SendToGitHub(chat_result, file_name, output_file_type)\n",
        "        else:\n",
        "          chat_result = chat_result.text\n",
        "      print(git_response)\n",
        "      #end if\n",
        "   # else:\n",
        "    #  git_response = ReadFileInGithub(file_name)\n",
        "     # file_content = decode_file_content(git_response)\n",
        "      #SendToGitHub(file_content, file_name)\n",
        "\n",
        "def ProcessDirRecursively(dir_to_process, instruction, gpt_model, input_file_type, output_file_type):\n",
        "  print(f'Processing directory: {dir_to_process}')\n",
        "  GetFolderFiles(dir_to_process)\n",
        "  to_process = GetFolderFiles(dir_to_process)\n",
        "  ProcessFiles(to_process, instruction, gpt_model, input_file_type, output_file_type)\n",
        "  sub_dirs = GetSubFolders(dir_to_process)\n",
        "  for sub_dir in sub_dirs:\n",
        "    ProcessDirRecursively(sub_dir, instruction, gpt_model, input_file_type, output_file_type)"
      ],
      "metadata": {
        "id": "D6QpMROhb9xl"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read Files and call GPT**"
      ],
      "metadata": {
        "id": "Vo1e05iMeTke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_stamp = GenerateTimestamp()\n",
        "gpt_model = \"gpt-3.5-turbo\"\n",
        "input_file_type = \".dpr\"\n",
        "output_file_type = \".py\"\n",
        "instruction_to_gpt = (\n",
        "    \"You are a Delphi-to-Python code converter. I will provide you with Delphi code, \"\n",
        "    \"and your task is to convert it to equivalent Python code.\\n\\n\"\n",
        "    \"- Do not include any explanations, comments, or formatting syntax (no triple backticks, no markdown).\\n\"\n",
        "    \"- Output only the Python and nothing else. Do not use markdown, code blocks, or extra formatting.\\n\"\n",
        "    \"- Add inline comments to explain parts of the code that are not easy to understand.\\n\"\n",
        "    \"- Match the logic and structure closely.\\n\"\n",
        "    \"- Use Pythonic idioms where appropriate.\\n\\n\"\n",
        "    \"Here is the Delphi code to convert:\\n\\n\"\n",
        ")\n",
        "\n",
        "ProcessDirRecursively(source_path, instruction_to_gpt, gpt_model, input_file_type, output_file_type)\n",
        "\n",
        "\n",
        "# this part is going to anotate and sugest improvements\n",
        "instruction_to_gpt = (\n",
        "    \"You are a Delphi code reviewer and annotator. I will provide you with Delphi source code.\\n\\n\"\n",
        "    \"- Keep the original Delphi code completely intact.\\n\"\n",
        "    \"- Add inline comments to explain what each part of the code is doing.\\n\"\n",
        "    \"- Where appropriate, add suggestions for potential improvements or refactors as comments.\\n\"\n",
        "    \"- Do not remove or modify any existing code.\\n\"\n",
        "    \"- Output only the Delphi code with your added comments, and nothing else. Do not use markdown, code blocks, or extra formatting.\\n\\n\"\n",
        "    \"Here is the Delphi code to annotate:\\n\\n\"\n",
        ")\n",
        "output_file_type = \".dpr\"\n",
        "ProcessDirRecursively(source_path, instruction_to_gpt, gpt_model, input_file_type, output_file_type)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXfXh413lJSD",
        "outputId": "c4024c17-42a6-4b96-c9c8-5fbb04121d7a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing directory: Console-Samples/010-StringComparison\n",
            "Sending ['Console-Samples/010-StringComparison/StringComparison.dpr', 'Console-Samples/010-StringComparison/StringComparison.dproj', 'Console-Samples/010-StringComparison/StringComparisonTurcFrench-01.png', 'Console-Samples/010-StringComparison/StringComparisonTurcFrench-02.png', 'Console-Samples/010-StringComparison/ToLower-ToLowerInvariant-ChatGPT-20250401.html'] to gpt\n",
            "{'content': {'name': 'StringComparison.py', 'path': 'Generated/20250514_040800/Console-Samples/010-StringComparison/StringComparison.py', 'sha': '3ba2333b121f0facaa45972c6cd60b6d73d9cbec', 'size': 1194, 'url': 'https://api.github.com/repos/josecascanteGL/chatGptPlayground/contents/Generated/20250514_040800/Console-Samples/010-StringComparison/StringComparison.py?ref=main', 'html_url': 'https://github.com/josecascanteGL/chatGptPlayground/blob/main/Generated/20250514_040800/Console-Samples/010-StringComparison/StringComparison.py', 'git_url': 'https://api.github.com/repos/josecascanteGL/chatGptPlayground/git/blobs/3ba2333b121f0facaa45972c6cd60b6d73d9cbec', 'download_url': 'https://raw.githubusercontent.com/josecascanteGL/chatGptPlayground/main/Generated/20250514_040800/Console-Samples/010-StringComparison/StringComparison.py?token=AOTJBBRD6NDFYE73YLEV7WLIEQLWC', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/josecascanteGL/chatGptPlayground/contents/Generated/20250514_040800/Console-Samples/010-StringComparison/StringComparison.py?ref=main', 'git': 'https://api.github.com/repos/josecascanteGL/chatGptPlayground/git/blobs/3ba2333b121f0facaa45972c6cd60b6d73d9cbec', 'html': 'https://github.com/josecascanteGL/chatGptPlayground/blob/main/Generated/20250514_040800/Console-Samples/010-StringComparison/StringComparison.py'}}, 'commit': {'sha': '6ed087cead74c245bf7824d4347abb9e0e225e17', 'node_id': 'C_kwDOOi8fENoAKDZlZDA4N2NlYWQ3NGMyNDViZjc4MjRkNDM0N2FiYjllMGUyMjVlMTc', 'url': 'https://api.github.com/repos/josecascanteGL/chatGptPlayground/git/commits/6ed087cead74c245bf7824d4347abb9e0e225e17', 'html_url': 'https://github.com/josecascanteGL/chatGptPlayground/commit/6ed087cead74c245bf7824d4347abb9e0e225e17', 'author': {'name': 'Jose Luis Cascante', 'email': 'jose.cascante@gorillalogic.com', 'date': '2025-05-14T04:08:05Z'}, 'committer': {'name': 'Jose Luis Cascante', 'email': 'jose.cascante@gorillalogic.com', 'date': '2025-05-14T04:08:05Z'}, 'tree': {'sha': '91d67a51c761a670b599e3e402e166511dd88302', 'url': 'https://api.github.com/repos/josecascanteGL/chatGptPlayground/git/trees/91d67a51c761a670b599e3e402e166511dd88302'}, 'message': 'Generated from ChatGPT', 'parents': [{'sha': '0625d6e5f04c07977daa4af26234a5fa332159c8', 'url': 'https://api.github.com/repos/josecascanteGL/chatGptPlayground/git/commits/0625d6e5f04c07977daa4af26234a5fa332159c8', 'html_url': 'https://github.com/josecascanteGL/chatGptPlayground/commit/0625d6e5f04c07977daa4af26234a5fa332159c8'}], 'verification': {'verified': False, 'reason': 'unsigned', 'signature': None, 'payload': None, 'verified_at': None}}}\n",
            "<Response [200]>\n",
            "Processing directory: Console-Samples/010-StringComparison\n",
            "Sending ['Console-Samples/010-StringComparison/StringComparison.dpr', 'Console-Samples/010-StringComparison/StringComparison.dproj', 'Console-Samples/010-StringComparison/StringComparisonTurcFrench-01.png', 'Console-Samples/010-StringComparison/StringComparisonTurcFrench-02.png', 'Console-Samples/010-StringComparison/ToLower-ToLowerInvariant-ChatGPT-20250401.html'] to gpt\n",
            "{'content': {'name': 'StringComparison.dpr', 'path': 'Generated/20250514_040800/Console-Samples/010-StringComparison/StringComparison.dpr', 'sha': '0ee6c6ebc33e774d3267e8d7c65a3d7b6193b282', 'size': 7026, 'url': 'https://api.github.com/repos/josecascanteGL/chatGptPlayground/contents/Generated/20250514_040800/Console-Samples/010-StringComparison/StringComparison.dpr?ref=main', 'html_url': 'https://github.com/josecascanteGL/chatGptPlayground/blob/main/Generated/20250514_040800/Console-Samples/010-StringComparison/StringComparison.dpr', 'git_url': 'https://api.github.com/repos/josecascanteGL/chatGptPlayground/git/blobs/0ee6c6ebc33e774d3267e8d7c65a3d7b6193b282', 'download_url': 'https://raw.githubusercontent.com/josecascanteGL/chatGptPlayground/main/Generated/20250514_040800/Console-Samples/010-StringComparison/StringComparison.dpr?token=AOTJBBW4HJUUPZGNYOECABLIEQLXA', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/josecascanteGL/chatGptPlayground/contents/Generated/20250514_040800/Console-Samples/010-StringComparison/StringComparison.dpr?ref=main', 'git': 'https://api.github.com/repos/josecascanteGL/chatGptPlayground/git/blobs/0ee6c6ebc33e774d3267e8d7c65a3d7b6193b282', 'html': 'https://github.com/josecascanteGL/chatGptPlayground/blob/main/Generated/20250514_040800/Console-Samples/010-StringComparison/StringComparison.dpr'}}, 'commit': {'sha': 'ff03e3a703dad8d56b9727e0cf07be3ed1557e09', 'node_id': 'C_kwDOOi8fENoAKGZmMDNlM2E3MDNkYWQ4ZDU2Yjk3MjdlMGNmMDdiZTNlZDE1NTdlMDk', 'url': 'https://api.github.com/repos/josecascanteGL/chatGptPlayground/git/commits/ff03e3a703dad8d56b9727e0cf07be3ed1557e09', 'html_url': 'https://github.com/josecascanteGL/chatGptPlayground/commit/ff03e3a703dad8d56b9727e0cf07be3ed1557e09', 'author': {'name': 'Jose Luis Cascante', 'email': 'jose.cascante@gorillalogic.com', 'date': '2025-05-14T04:08:19Z'}, 'committer': {'name': 'Jose Luis Cascante', 'email': 'jose.cascante@gorillalogic.com', 'date': '2025-05-14T04:08:19Z'}, 'tree': {'sha': '1063966f014ce8950d77fc00a2e632bc77b086b4', 'url': 'https://api.github.com/repos/josecascanteGL/chatGptPlayground/git/trees/1063966f014ce8950d77fc00a2e632bc77b086b4'}, 'message': 'Generated from ChatGPT', 'parents': [{'sha': '6ed087cead74c245bf7824d4347abb9e0e225e17', 'url': 'https://api.github.com/repos/josecascanteGL/chatGptPlayground/git/commits/6ed087cead74c245bf7824d4347abb9e0e225e17', 'html_url': 'https://github.com/josecascanteGL/chatGptPlayground/commit/6ed087cead74c245bf7824d4347abb9e0e225e17'}], 'verification': {'verified': False, 'reason': 'unsigned', 'signature': None, 'payload': None, 'verified_at': None}}}\n",
            "<Response [200]>\n"
          ]
        }
      ]
    }
  ]
}